{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /home/sandheepgopinath/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
      "local data directory. If you'd instead prefer to read directly from our public\n",
      "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
      "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbdba052bf49433bb09c00cbd54b7cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptioâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1mDataset mnist downloaded and prepared to /home/sandheepgopinath/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mnist_dataset,mnist_info=tfds.load(name='mnist',with_info=True,as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tensor flow has only train and test datasets\n",
    "#An arbitary percentage of train can be used to split into validation\n",
    "\n",
    "mnist_train, mnist_test=mnist_dataset['train'],mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_info.splits['train'].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_validation=0.1*mnist_info.splits['train'].num_examples\n",
    "\n",
    "#Here there might be floating point numbers\n",
    "\n",
    "n_validation=tf.cast(n_validation,tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test=mnist_info.splits['test'].num_examples\n",
    "n_test=tf.cast(n_test,tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling an images to 0,1 range. Hence it has to be in Float \n",
    "\n",
    "def scale(image, label):\n",
    "    image=tf.cast(image,tf.float32)\n",
    "    image/=255. # The dot specifies that we need the output in Float\n",
    "    return image, label\n",
    "#Here the function only transforms as it takes and returns the same things\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THe map function in TF can be used to apply a custom transformation, but it needs an image and label\n",
    "\n",
    "\n",
    "mnist_train_scaled=mnist_train.map(scale)\n",
    "mnist_test_scaled=mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling helps if the data is ordered.\n",
    "\n",
    "def shuffleAndSplit(Train_data,BUFFER_SIZE,BATCH_SIZE,Split_percentage,Test_data,Batch=False,):\n",
    "    shuffled_data=Train_data.shuffle(BUFFER_SIZE)\n",
    "    validation_data=shuffled_data.take(Split_percentage)\n",
    "    train_data=shuffled_data.skip(Split_percentage)\n",
    "    if Batch==True:\n",
    "        train_data=train_data.batch(BATCH_SIZE)\n",
    "        validation_data=validation_data.batch(BATCH_SIZE)\n",
    "        test_data=Test_data.batch(BATCH_SIZE)\n",
    "    return train_data,validation_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test,validation=shuffleAndSplit(mnist_train_scaled,10000,100,n_validation,mnist_test_scaled,Batch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the input and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_input,validation_targets=next(iter(validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential()\n",
    "\n",
    "#Adding layers to the model\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28,1)))\n",
    "model.add(tf.keras.layers.Dense(512,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(256,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "540/540 [==============================] - 5s 9ms/step - loss: 0.2694 - accuracy: 0.9181 - val_loss: 0.1024 - val_accuracy: 0.9600\n",
      "Epoch 2/10\n",
      "540/540 [==============================] - 3s 5ms/step - loss: 0.0997 - accuracy: 0.9698 - val_loss: 0.1209 - val_accuracy: 0.9700\n",
      "Epoch 3/10\n",
      "489/540 [==========================>...] - ETA: 0s - loss: 0.0658 - accuracy: 0.9797"
     ]
    }
   ],
   "source": [
    "model.fit(train,epochs=10,validation_data=(validation_input,validation_targets),validation_steps=1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
